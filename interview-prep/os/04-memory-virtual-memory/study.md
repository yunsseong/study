# 4. 메모리 관리와 가상 메모리

---

## 메모리 관리가 왜 필요한가?

```
물리 메모리(RAM): 16GB
실행 중인 프로그램: Chrome(4GB) + IntelliJ(3GB) + Spring Boot(2GB) + ...

문제:
1. 메모리가 부족하면? → 프로그램 실행 불가
2. 프로그램들이 서로 메모리를 침범하면? → 보안/안정성 문제
3. 메모리를 효율적으로 쓰려면? → OS가 관리해야 함
```

---

## 메모리 주소

### 논리적 주소 vs 물리적 주소

```
프로그램이 보는 주소 (논리적): 0x0000 ~ 0xFFFF (각 프로그램마다 0부터 시작)
실제 RAM 주소 (물리적):       0x3A00 ~ 0x4AFF (실제 메모리 위치)

MMU(Memory Management Unit)가 변환:
논리적 주소 → [MMU] → 물리적 주소
```

왜 분리하는가?
- 프로그램은 항상 0번지부터 시작한다고 생각하고 코딩할 수 있음
- OS가 실제 메모리 배치를 자유롭게 변경 가능
- 프로그램 간 메모리 보호 가능

---

## 메모리 할당 방식

### 연속 할당

프로세스를 메모리에 **연속된 공간**에 배치.

```
메모리: [OS][  P1  ][    P2    ][  P3  ][        빈 공간        ]
```

문제: **외부 단편화(External Fragmentation)**

```
P2 종료 후:
메모리: [OS][  P1  ][   빈    ][  P3  ][        빈 공간        ]
                    ↑ 10MB 빈 공간

새 프로그램 P4(15MB)를 실행하고 싶은데,
빈 공간이 10MB + 빈 공간이 합쳐서 충분해도
연속된 15MB가 없어서 실행 불가!
```

### 비연속 할당: 페이징

메모리를 **고정 크기 블록(페이지)**으로 나누어 관리.

```
논리 메모리 (프로세스)        물리 메모리 (RAM)
┌─────────┐                ┌─────────┐
│ 페이지 0 │ ───────────→  │ 프레임 5 │
├─────────┤                ├─────────┤
│ 페이지 1 │ ────┐         │ 프레임 1 │ ← 페이지 2
├─────────┤     │         ├─────────┤
│ 페이지 2 │ ─┐  │         │ 프레임 2 │
├─────────┤  │  │         ├─────────┤
│ 페이지 3 │  │  └──────→  │ 프레임 3 │ ← 페이지 1
└─────────┘  │            ├─────────┤
             └──────────→ │ 프레임 8 │ ← 페이지 2
                          └─────────┘
```

- **페이지**: 논리 메모리의 고정 크기 블록 (보통 4KB)
- **프레임**: 물리 메모리의 같은 크기 블록
- **페이지 테이블**: 페이지 → 프레임 매핑 정보
- 외부 단편화 없음!
- 대신 **내부 단편화** 발생 가능 (페이지 안에 남는 공간)

---

## 가상 메모리 (Virtual Memory)

### 핵심 아이디어

물리 메모리(RAM)보다 **더 큰 프로그램**을 실행할 수 있게 하는 기술.

```
RAM: 4GB
프로그램: 8GB

가상 메모리 없이: 실행 불가
가상 메모리 사용: 필요한 부분만 RAM에 올리고, 나머지는 디스크에 저장 → 실행 가능!
```

### 동작 원리: Demand Paging

**필요한 페이지만** 메모리에 올린다. 나머지는 디스크(스왑 영역)에 있다.

```
프로그램의 전체 페이지: [0][1][2][3][4][5][6][7]

RAM에 올라온 것:  [0][2][5]     ← 최근 사용한 것
디스크에 있는 것:  [1][3][4][6][7] ← 아직 안 쓰거나 오래된 것
```

---

## 페이지 폴트 (Page Fault)

CPU가 접근하려는 페이지가 RAM에 없을 때 발생.

```
1. CPU: "페이지 3 접근!" → 페이지 테이블 확인
2. 페이지 테이블: "페이지 3은 RAM에 없음" → 페이지 폴트 발생!
3. OS: 디스크에서 페이지 3을 읽어옴
4. RAM의 빈 프레임에 페이지 3 적재
5. 페이지 테이블 업데이트
6. CPU: 다시 페이지 3 접근 → 성공!
```

**페이지 폴트가 많으면?**
- 디스크 I/O가 빈번 → 매우 느림 (RAM 접근: ~100ns, 디스크: ~10ms = 10만 배 차이)
- **스래싱(Thrashing)**: 페이지 폴트가 너무 자주 발생하여 실제 작업보다 페이지 교체에 시간을 더 쓰는 현상

---

## 페이지 교체 알고리즘

RAM이 꽉 찼는데 새 페이지를 올려야 할 때, **어떤 페이지를 내릴 것인가?**

### FIFO (First In, First Out)

가장 먼저 들어온 페이지를 교체.

```
페이지 참조: 1, 2, 3, 4, 1, 2, 5, 1, 2, 3
프레임 3개:

[1][ ][ ] → [1][2][ ] → [1][2][3] → [4][2][3] → [4][1][3] → ...
 ↑ 먼저 들어온 것부터 교체
```

- 구현 간단
- 단점: **Belady's Anomaly** - 프레임을 늘려도 페이지 폴트가 증가할 수 있음

### LRU (Least Recently Used)

**가장 오래 전에 사용된** 페이지를 교체. 가장 널리 사용되는 알고리즘.

```
최근 사용 순서: 페이지 5 > 3 > 1 > 2
                (최근)          (오래됨)

새 페이지 필요 → 가장 오래된 페이지 2를 교체
```

- "최근에 쓴 건 곧 다시 쓸 가능성이 높다" (시간적 지역성)
- 실무에서 가장 많이 사용
- **Redis의 캐시 만료 정책도 LRU를 사용** (면접 연결 포인트!)

### LFU (Least Frequently Used)

사용 횟수가 가장 적은 페이지를 교체.

### OPT (Optimal)

앞으로 가장 오래 사용되지 않을 페이지를 교체. 이론상 최적이지만 미래를 알 수 없으므로 구현 불가.

---

## TLB (Translation Lookaside Buffer)

페이지 테이블 조회를 빠르게 하기 위한 **캐시**.

```
주소 변환 과정:
논리 주소 → TLB 확인 → 히트? → 바로 물리 주소 (빠름)
                      미스? → 페이지 테이블 조회 → 물리 주소 (느림)
```

- TLB 히트: ~1ns
- 페이지 테이블 조회: ~100ns
- **컨텍스트 스위칭 시 TLB가 무효화** → 프로세스 전환이 비싼 이유 중 하나

---

## Spring Boot / 실무 연결

### JVM 메모리와 가상 메모리

```
Spring Boot 실행 시:
java -Xms512m -Xmx2g -jar myapp.jar

-Xms512m: 초기 힙 크기 512MB
-Xmx2g:   최대 힙 크기 2GB

JVM이 요청한 2GB가 모두 물리 메모리에 올라가는 건 아니다.
OS의 가상 메모리가 필요한 부분만 물리 메모리에 올린다.
```

### Redis와 LRU

```
Redis 캐시 설정:
maxmemory 256mb
maxmemory-policy allkeys-lru

→ 메모리가 256MB를 초과하면 LRU 정책으로 오래된 캐시를 삭제
→ OS의 페이지 교체 알고리즘과 같은 원리!
```

### OOM (Out of Memory)

```
Spring Boot 서버에서 메모리 누수 발생
→ Heap이 계속 증가
→ GC로도 해결 안 됨
→ java.lang.OutOfMemoryError
→ OS가 프로세스를 강제 종료할 수도 있음 (OOM Killer)
```

---

## 면접 핵심 정리

**Q: 가상 메모리란 무엇인가요?**
> 물리 메모리(RAM)보다 큰 프로그램을 실행할 수 있게 하는 기술입니다.
> 프로그램의 전체를 메모리에 올리지 않고, 필요한 페이지만 RAM에 올리고
> 나머지는 디스크에 저장합니다.
> 이를 Demand Paging이라 하며, 접근하려는 페이지가 RAM에 없으면
> 페이지 폴트가 발생하여 디스크에서 가져옵니다.

**Q: 페이지 교체 알고리즘 중 LRU를 설명해주세요**
> 가장 오래 전에 사용된 페이지를 교체하는 알고리즘입니다.
> "최근에 사용된 페이지는 곧 다시 사용될 가능성이 높다"는
> 시간적 지역성(Temporal Locality) 원리를 활용합니다.
> 실무에서 가장 많이 사용되며, Redis의 캐시 만료 정책도 LRU를 사용합니다.

**Q: 스래싱(Thrashing)이란 무엇인가요?**
> 페이지 폴트가 너무 빈번하게 발생하여, 실제 작업보다
> 페이지 교체(디스크 I/O)에 더 많은 시간을 소비하는 현상입니다.
> 프로세스에 할당된 물리 메모리가 너무 적을 때 발생합니다.
> 해결 방법으로는 물리 메모리 증가, 프로세스 수 줄이기, Working Set 보장 등이 있습니다.

**Q: 컨텍스트 스위칭 시 메모리 관점에서 어떤 비용이 드나요?**
> 프로세스 전환 시 페이지 테이블을 교체하고, TLB가 무효화됩니다.
> TLB가 비워지면 이후 메모리 접근마다 TLB 미스가 발생하여 느려집니다.
> 스레드 전환은 같은 프로세스 내이므로 페이지 테이블과 TLB를 유지할 수 있어 빠릅니다.
